{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae926b2-fa06-4f00-b18d-7f74e92ce676",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NovaSAR-1 data products <img align=\"right\" src=\"../../resources/csiro_easi_logo.png\">\n",
    "\n",
    "#### Index\n",
    "- [Overview](#Overview)\n",
    "   - [Tips and tricks](#Tips-and-tricks)\n",
    "   - [Background on SAR data](#Background-on-SAR-data)\n",
    "- [Setup (imports, defaults, dask, odc)](#Setup)\n",
    "- [Example query](#Example-query)\n",
    "- [Product definition](#Product-definition)\n",
    "- [Quality layer](#Quality-layer)\n",
    "- [Create and apply a good quality pixel mask](#Create-and-apply-a-good-quality-pixel-mask)\n",
    "- [Plot and browse the data](#Plot-and-browse-the-data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23474415-05a4-4065-b28a-3acbe7129f7f",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to load and use NovaSAR-1 ARD _gamma-0 backscatter_ data products from the [CSIRO NovaSAR Facility](https://research.csiro.au/cceo/novasar/).\n",
    "\n",
    "The [NovaSAR-1 data products](https://research.csiro.au/cceo/novasar/about/novasar-1-user-guide/#products) include:\n",
    "- Level-1 product types Multi-Look Detected (GRD, SCD, SRD) and Single Look Complex (SLC)\n",
    "- Level-2 analysis ready data (ARD) gamma-0 radiometric terrain corrected backscatter\n",
    "\n",
    "The **Level-1** data products are stored in swath (line, row) raster grids, with a \"fake\" WGS-84 bounding box grid for ODC indexing. This means they are not suited to `datacube.load()` directly. Instructions TBC.\n",
    "\n",
    "The **Level-2 ARD** data products are remapped to WGS-84 grids (various resolutions) as part of the gamma-0 backscatter processing. These data can be opened directly with `datacube.load()`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35b91cdb-2c5a-48c0-a0bf-7de2c2637bc5",
   "metadata": {},
   "source": [
    "## Tips and tricks\n",
    "\n",
    "#### 1. NovaSAR-1 product names\n",
    "\n",
    "The ODC currently requires a “dataset” to contain all bands that are defined for its parent product. In practice, each of the NovaSAR-1 product types (GRD, SCD, SRD, SLC, ARD) can have different combinations of available polarization bands across all scene acquisitions. This means we need multiple ODC products; one for each combination of polarizations.\n",
    "\n",
    "> WIP: relax this constraint in ODC so that we can have \"optional\" bands defined, which will allow us to aggregate polarization combinations for a single product type.\n",
    "\n",
    "View the coverage of indexed NovaSAR-1 products and datasets in the [CSIRO EASI Explorer \"SAR products group\"](https://explorer.csiro.easi-eo.solutions/products#synthetic-aperture-radar-sar-group).\n",
    "\n",
    "#### 2. Load to target grid or crs/resolution\n",
    "\n",
    "Different scenes (ODC datasets) in a product may have different spatial resolutions depending on the acquisition mode, so its usually appropriate to provide a target grid. For example, use either\n",
    "\n",
    "- `datacube.load(..., like=target_geobox)`. See [odc-geo](https://github.com/opendatacube/odc-geo) to help create a target \"geobox\", or use an existing (ODC-compatible) xarray object\n",
    "- `datacube.load(..., output_crs=target_crs, resolution=target_res, align=target_res/2)`\n",
    "\n",
    "For convenience and general applicability, default load parameters are defined for all NovaSAR-1 L2 ARD products as:\n",
    "\n",
    "- `CRS = \"epsg:4326\" (WGS-84)`, `Pixel_size = 0.0002 deg` (20 m) and `Align = 0.0001` (10 m). \n",
    "\n",
    "This means a `datacube.load()` call without specific output grid parameters (no `like`, `output_crs`, `resolution`) will load data into a _WGS-84, 20 m, aligned to pixel centres_ grid with extents given by the `latitude/longitude/x/y/crs` parameters.\n",
    "\n",
    "> Native NovaSAR-1 L2 ARD products are aligned to pixel centres (AREA_OR_POINT=Point). You should ensure this is taken into account if mapping pixels to a target grid that is approximately the same resolution as the native scene resolution (otherwise you may be shifting by half-pixel). If mapping to a coarser resolution if may not matter as much.\n",
    "\n",
    "#### 3. Select or filter scenes before loading\n",
    "\n",
    "Scenes can be pre-filtered using the scene metadata and the `datacube.find_datasets()` function before datasets are loaded into an xarray object. There are two easy (and similar) ways to achieve this:\n",
    "\n",
    "1. Use `datacube.find_datasets()` with _product, time, space_ search parameters. This returns a list of dataset items that can be filtered manually, e.g. by scene name or scene metadata. Pass your filtered list to `datacube.load(datasets=my_datasets_list, like=target_geobox)`.\n",
    "   - This is demonstrated below by parsing likely useful metadata for a list of datasets items into a pandas table, for viewing.\n",
    "1. Create a metadata predicate function that returns `True` if a dataset's metadata satisifies the conditions specified in your function. This predicate function can be passed to `datacube.load(..., dataset_predicate=my_filter_function`), which is then applied internally in a call to `find_datasets`. See [datacube.load() help](https://opendatacube.readthedocs.io/en/latest/api/indexed-data/generate/datacube.Datacube.load.html) for an example.\n",
    "\n",
    "#### 4. Units and conversions\n",
    "The `novasar_l2ard_*` data are given in _Digital numbers_ (DN). DNs can be converted to _decibel (dB)_ or _linear amplitude_, and vice-versa, with the following equations. Practical _Xarray_ examples are given below.\n",
    "\n",
    "Amplitude to/from dB:\n",
    "```\n",
    "dB = 20 * log10(DN) + K\n",
    "DN = 10^((dB-K)/20)\n",
    "\n",
    "where K is a calibration factor, which for NovaSAR-1 is -83 dB.\n",
    "```\n",
    "\n",
    "Digital numbers to/from Amplitude:\n",
    "```\n",
    "amplitude = DN / 14125.3754\n",
    "DN = amplitude * 14125.3754\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5120c6-e943-46a9-a4d8-c5b759586e62",
   "metadata": {},
   "source": [
    "## Background on SAR data\n",
    "\n",
    "An excellent introduction and overview to using SAR data is provided in the [CEOS Laymans SAR Interpretation Guide](https://ceos.org/ard/files/Laymans_SAR_Interpretation_Guide_3.0.pdf). This guide has also been converted to a set of set of Jupyter notebooks that you can download from https://github.com/AMA-Labs/cal-notebooks/tree/main/examples/SAR.\n",
    "\n",
    "The SAR instrument on the NovaSAR-1 satellite operates in the ***S-band at approximately 9.4 cm wavelength***. This means that it can \"see\" objects of about this size and larger, and smaller objects are relatively transparent. Compared to *Sentinel-1 (C-band, 5.6 cm)*, NovaSAR S-band is less sensitive to tree canopies and has better ground penetration.\n",
    "\n",
    "> The SAR signal responds to the orientation and scattering from surface features of comparable size or larger than the wavelength.\n",
    "> - A bright backscatter value typically means the surface was orientated perpendicular to the signal incidence angle and most of the signal was reflected back to the satellite (direct backscatter)\n",
    "> - A dark backscatter value means most of the signal was reflected away from the satellite (forward scattering) and typically responds to a smooth surface (relative to the wavelength) such as calm water or bare soil\n",
    "> - Rough surfaces (relative to the wavelength) result in diffuse scattering where some of the signal is returned to the satellite.\n",
    "> - Complex surfaces may result in volume scattering (scattering within a tree canopy) or double-bounce scattering (perpendicular objects such as buildings and structures)\n",
    "> - The relative backscatter values of co-polarisation (HH, VV) and cross-polarisation (HV) measurements can provide information on the scattering characteristics of the surface features.\n",
    "\n",
    "Using NovaSAR-1 backscatter data requires interpretation of the data for different surface features, including as these features change spatially or in time. It may also be necessary to carefully consider the incidence angle of the SAR signal relative to the surface features using the *incidence_angle* band or the satellite direction metadata (descending = north to south; ascending = south to north)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c0ff4-e1a2-4adf-98d1-1ca5b9f3126d",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7c012-719e-4f13-a206-36f271c6a91c",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c848c17-2e7c-4b68-9682-b8994644f521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Common imports and settings\n",
    "import os, sys, re\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "# Datacube\n",
    "import datacube\n",
    "from datacube.utils.aws import configure_s3_access\n",
    "import odc.geo.xr                             # https://github.com/opendatacube/odc-geo\n",
    "from datacube.utils import masking            # https://github.com/opendatacube/datacube-core/blob/develop/datacube/utils/masking.py\n",
    "from dea_tools.plotting import display_map    # https://github.com/GeoscienceAustralia/dea-notebooks/tree/develop/Tools\n",
    "\n",
    "# Dask\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "# Basic plots\n",
    "%matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = [12, 8]\n",
    "\n",
    "# Holoviews\n",
    "# https://holoviz.org/tutorial/Composing_Plots.html\n",
    "# https://holoviews.org/user_guide/Composing_Elements.html\n",
    "import hvplot.xarray\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "from datashader import reductions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde8313b-887d-4529-bd57-89f740ff6380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EASI defaults and convenience functions\n",
    "# easi-tools is in the repo https://github.com/csiro-easi/easi-notebooks\n",
    "# These are convenience functions for using these notebooks in EASI; comment-out if not required\n",
    "\n",
    "repo = Path.home() / 'easi-notebooks'    # Change path as necessary\n",
    "if str(repo) not in sys.path:\n",
    "    sys.path.append(str(repo))\n",
    "\n",
    "from easi_tools import initialize_dask, xarray_object_size  # Useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66366a-f2d5-461a-a34f-7eed5a5296fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Dask cluster\n",
    "\n",
    "Using a local _Dask_ cluster is a good habit to get into. It can simplify loading and processing of data in many cases, and it provides a dashboard that shows the loading/processing progress.\n",
    "\n",
    "To learn more about _Dask_ see the set of [dask notebooks](https://github.com/csiro-easi/easi-notebooks/tree/main/html#dask-tutorials)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9e778-755c-4ff2-a99f-ad5c48438665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Local cluster - good for small exploratory and testing work\n",
    "cluster, client = initialize_dask(workers=8)\n",
    "display(client)\n",
    "\n",
    "# Or use Dask Gateway - this may take a few minutes\n",
    "# cluster, client = initialize_dask(use_gateway=True, workers=4)\n",
    "# display(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746582e-be79-448c-a9c4-7a2ae2d703ce",
   "metadata": {},
   "source": [
    "#### ODC database\n",
    "\n",
    "Connect to the ODC database. Configure the environment and low-level tools to read from AWS buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2232ee-f0a5-43fc-a6c6-d422b437cd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube()\n",
    "\n",
    "# Access AWS \"requester-pays\" buckets\n",
    "# This is necessary for reading data from most third-party AWS S3 buckets such as for Landsat and Sentinel-2\n",
    "configure_s3_access(aws_unsigned=False, requester_pays=True, client=client);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1801db2b-e24e-45fa-85d4-e153ebcc8f6f",
   "metadata": {},
   "source": [
    "## Example query\n",
    "\n",
    "Change any of the parameters in the `query` object below to adjust the location, time, projection, or spatial resolution of the returned datasets.\n",
    "\n",
    "Use the Explorer interface to check the temporal and spatial coverage for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04d875-20d4-4d72-a16d-e76b7f48161c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set your own latitude / longitude\n",
    "\n",
    "# Menindee Lakes, Australia\n",
    "latitude_range = (-32.1, -33.6)\n",
    "longitude_range = (141.5, 143)\n",
    "\n",
    "# Great Western Woodlands, Australia\n",
    "# latitude_range = (-33, -32.6)\n",
    "# longitude_range = (120.5, 121)\n",
    "\n",
    "time_range = None   # All available times\n",
    "\n",
    "available_ard_products = [\n",
    "    'novasar_l2ard_hh',         # Moderate coverage, https://explorer.csiro.easi-eo.solutions/products/novasar_l2ard_hh\n",
    "    'novasar_l2ard_hh_hv',      # High coverage, https://explorer.csiro.easi-eo.solutions/products/novasar_l2ard_hh_hv\n",
    "    'novasar_l2ard_hv',         # Low coverage, https://explorer.csiro.easi-eo.solutions/products/novasar_l2ard_hv\n",
    "    'novasar_l2ard_vv',         # Moderate coverage, https://explorer.csiro.easi-eo.solutions/products/novasar_l2ard_vv\n",
    "    'novasar_l2ard_vv_hh',      # Moderate coverage, https://explorer.csiro.easi-eo.solutions/products/novasar_l2ard_vv_hh\n",
    "    'novasar_l2ard_vv_hh_hv',   # High coverage, https://explorer.csiro.easi-eo.solutions/products/novasar_l2ard_vv_hh_hv\n",
    "]\n",
    "\n",
    "# Select a product\n",
    "product_name = 'novasar_l2ard_hh_hv'\n",
    "polarizations = re.findall('_([vh]+)', product_name)  # The set of polarization bands for the selected product\n",
    "\n",
    "query = {\n",
    "    'product': product_name,       # Product name\n",
    "    'measurements': polarizations + ['angle', 'mask', 'scatteringarea', 'gammatosigmaratio'],  # All bands for testing\n",
    "    'x': longitude_range,     # \"x\" axis bounds\n",
    "    'y': latitude_range,      # \"y\" axis bounds\n",
    "    'time': time_range,       # Any parsable date strings\n",
    "}\n",
    "\n",
    "# Convenience function to display the selected area of interest\n",
    "display_map(longitude_range, latitude_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399fe85-ba78-4a8e-8a33-3dcdfa95b7f2",
   "metadata": {},
   "source": [
    "## Review scene metadata for the query\n",
    "\n",
    "Run `datacube.find_datasets()` for the query and summarise resulting scene information in a pandas table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84334a-1749-412c-b10c-e7bbc53c43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dc.find_datasets(**query)\n",
    "\n",
    "# Examples\n",
    "# datasets[0].metadata_doc --> dict of all metadata\n",
    "# datasets[0].measurements --> dict of measurements\n",
    "# datasets[0].grids --> dict of grids (shape and transform) defined for measurements\n",
    "# datasets[0].crs --> CRS object\n",
    "# datasets[0].extent --> geometry object\n",
    "# datasets[0].time --> start and end time objects\n",
    "# datasets[0].properties --> dict of properties\n",
    "\n",
    "# Select your own fields\n",
    "fields = {\n",
    "    'name': None,\n",
    "    'time': None,\n",
    "    'gsd': None,\n",
    "    'polarizations': None,\n",
    "    'pass_direction': None,\n",
    "    'antenna_pointing': None,\n",
    "    'platform_heading': None,\n",
    "    'incident_angle_near_range': None,\n",
    "    'incident_angle_far_range': None,\n",
    "    'source_product_level': None,\n",
    "    'operational_mode_name': None,\n",
    "    'filter_applied': None,\n",
    "    'noise_removal_applied': None,\n",
    "}\n",
    "\n",
    "# Parse into a pandas DataFrame\n",
    "df = []\n",
    "for ds in datasets:\n",
    "    ff = fields.copy()\n",
    "    # Non-properties fields\n",
    "    ff['name'] = ds.metadata.label\n",
    "    ff['time'] = ds.time[0]  # time->range(start, end) or center_time->(end-start)/2\n",
    "    # Properties fields\n",
    "    for xx in fields:\n",
    "        if xx in ('name', 'time'):\n",
    "            continue\n",
    "        pre = 'eo' if xx == 'gsd' else 'novasar'\n",
    "        ff[xx] = ds.properties[f\"{pre}:{xx}\"]\n",
    "    df.append(ff)\n",
    "df = pd.DataFrame(df)\n",
    "display(df.sort_values('time') if not df.empty else Markdown(\"**Dataframe is empty**. Choose different product, space, time parameters\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f263ddb-f156-4841-8a01-9ced702cc820",
   "metadata": {},
   "source": [
    "## Filter scenes based on metadata only\n",
    "\n",
    "This step is optional and configurable. Here we show a selection of simple filters:\n",
    "\n",
    "- Select descending passes only\n",
    "- Select the N most recent scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b759fa-21d1-4d4b-929a-38927e6e0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_datasets = datasets  # Start with the full list\n",
    "\n",
    "# Select descending passes only\n",
    "selected_datasets = [\n",
    "    xx for xx in selected_datasets if xx.properties[\"novasar:pass_direction\"] == \"DESCENDING\"\n",
    "]\n",
    "\n",
    "# Select the N most recent scenes\n",
    "selected_datasets = sorted(selected_datasets, key=lambda ds: ds.time[0])[-10:]\n",
    "\n",
    "display(Markdown(f\"**Number of selected scenes**: {len(selected_datasets)}\"))\n",
    "selected_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fefeef8-0c21-49c2-b86f-c68e5178a7ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load data into a virtual dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4c724f-636a-4833-a165-adb053acaa07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Target xarray parameters\n",
    "# - Target GeoBox or output CRS and resolution\n",
    "# - Usually we group input scenes on the same day to a single time layer (groupby)\n",
    "# - Select a reasonable Dask chunk size. This should be adjusted depending on the spatial extents and target grid parameters you choose\n",
    "\n",
    "# Default target grid is WGS-84, 20 m pixels for the given spatial extents\n",
    "# - Create or reuse a GeoBox for precise mapping of input pixels to a target grid\n",
    "# - Or provide output_crs and resolution, which will create best-fit GeoBox\n",
    "\n",
    "# Example similar Geobox constructor\n",
    "# geobox = odc.geo.geobox.GeoBox.from_bbox(\n",
    "#     [query['x'][0], query['y'][1], query['x'][1], query['y'][0]],\n",
    "#     crs='epsg:4326', resolution=0.0002, anchor=0.0001\n",
    "# )\n",
    "\n",
    "load_params = {\n",
    "    'datasets': selected_datasets,\n",
    "    'group_by': 'solar_day',                        # Scene grouping\n",
    "    'dask_chunks': {'latitude':2048, 'longitude':2048},      # Dask chunks\n",
    "}\n",
    "\n",
    "# Load data\n",
    "data = dc.load(**(query | load_params))\n",
    "\n",
    "display(xarray_object_size(data))\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d86506-39ba-4f02-ac6e-2d1d27119668",
   "metadata": {},
   "source": [
    "## Conversion and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99eb8a2c-fe00-44b7-bd39-250ab3d323cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# These functions use numpy, which should be satisfactory for most notebooks.\n",
    "# Calculations for larger or more complex arrays may require Xarray's \"ufunc\" capability.\n",
    "# https://docs.xarray.dev/en/stable/examples/apply_ufunc_vectorize_1d.html\n",
    "#\n",
    "# Apply numpy.log10 to the DataArray\n",
    "# log10_data = xr.apply_ufunc(np.log10, data)\n",
    "\n",
    "def dn_to_decibel(da: 'xr.DataArray', K=0):\n",
    "    \"\"\"Return an array converted to dB values\"\"\"\n",
    "    xx = da.where(da > 0, np.nan)  # Set values <= 0 to NaN\n",
    "    xx = 20*np.log10(xx) + K\n",
    "    xx.attrs.update({\"units\": \"dB\"})\n",
    "    return xx\n",
    "\n",
    "def decibel_to_dn(da: 'xr.DataArray', K=0):\n",
    "    \"\"\"Return an array converted to digital number values\"\"\"\n",
    "    xx = np.power(10, (da-K)/20.0)\n",
    "    xx.attrs.update({\"units\": \"DN\"})\n",
    "    return xx\n",
    "\n",
    "def dn_to_amplitude(da: 'xr.DataArray'):\n",
    "    \"\"\"Return an array converted to linear amplitude values\"\"\"\n",
    "    scale_factor = da.attrs['scale_factor'] if 'scale_factor' in da.attrs else 1\n",
    "    # print(f\"DN to amplitude scale_factor: 1/{1/scale_factor} = {scale_factor}\")\n",
    "    xx = da.where(da > 0, np.nan)  # Set values <= 0 to NaN\n",
    "    xx = xx * scale_factor\n",
    "    xx.attrs.update({\"units\": \"amplitude\"})\n",
    "    return xx\n",
    "\n",
    "def select_valid_time_layers(ds: 'xarray', percent: float = 5):\n",
    "    \"\"\"Select time layers that have at least a given percentage of valid data (e.g., >=5%)\n",
    "\n",
    "    Example usage:\n",
    "      selected = select_valid_time_layers(ds, percent=5)\n",
    "      filtered == ds.sel(time=selected)\n",
    "    \"\"\"\n",
    "    spatial_dims = ds.odc.spatial_dims\n",
    "    nelements = ds.sizes[spatial_dims[0]] * ds.sizes[spatial_dims[1]]\n",
    "    if ds.dtype =='bool':\n",
    "        return ds.sum(dim=spatial_dims).values / nelements >= (percent/100.0)\n",
    "    return ds.count(dim=spatial_dims).values / nelements >= (percent/100.0)\n",
    "\n",
    "# Examples to check that the intensity to/from dB functions work as expected\n",
    "# xx = data.vv.isel(time=0,latitude=np.arange(0, 5),longitude=np.arange(0, 5))\n",
    "# xx[0] = 0       # manually change some values\n",
    "# xx[1] = -0.001  # manually change some values\n",
    "# display(\"digital numbers:\", xx.values)\n",
    "# yy = dn_to_decibel(xx, K=-83)\n",
    "# display(\"decibels:\", yy.values)\n",
    "# zz = decibel_to_dn(yy, K=-83)\n",
    "# display(\"digital numbers:\", zz.values)\n",
    "# aa = dn_to_amplitude(xx)\n",
    "# display(\"amplitude:\", aa.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bcf24c-99bb-4986-9afd-3a6e63b9a8cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# hvPlot convenience functions\n",
    "def make_image(ds: 'xarray', frame_height=300, **kwargs):\n",
    "    \"\"\"Return a Holoviews DynamicMap (image) object that can be displayed or combined\"\"\"\n",
    "    spatial_dims = ds.odc.spatial_dims\n",
    "    defaults = dict(\n",
    "        cmap=\"Greys_r\",\n",
    "        y = spatial_dims[0], x = spatial_dims[1],\n",
    "        groupby = 'time',\n",
    "        rasterize = True,\n",
    "        geo = True,\n",
    "        robust = True,\n",
    "        frame_height = frame_height,\n",
    "        clabel = ds.attrs.get('units', None),\n",
    "    )\n",
    "    defaults.update(**kwargs)\n",
    "    return ds.hvplot.image(**defaults)\n",
    "\n",
    "def rgb_image(ds: 'xarray', frame_height=300, **kwargs):\n",
    "    \"\"\"Return a Holoviews DynamicMap (RBG image) object that can be displayed or combined\"\"\"\n",
    "    spatial_dims = ds.odc.spatial_dims\n",
    "    defaults = dict(\n",
    "        bands='band',\n",
    "        y = spatial_dims[0], x = spatial_dims[1],\n",
    "        groupby = 'time',\n",
    "        rasterize = True,\n",
    "        geo = True,\n",
    "        robust = True,\n",
    "        frame_height = frame_height,\n",
    "    )\n",
    "    defaults.update(**kwargs)\n",
    "    return ds.hvplot.rgb(**defaults)\n",
    "\n",
    "def mask_image(ds: 'xarray', frame_height=300, **kwargs):\n",
    "    \"\"\"Return a Holoviews DynamicMap (mask image) object that can be displayed or combined\"\"\"\n",
    "    # NovaSAR ARD mask\n",
    "    color_def = [\n",
    "        (0,  '#ff0004', 'InvalidData'),   # red\n",
    "        (1,  '#eeeeee', 'ValidData'),   # light grey\n",
    "        (5, '#ff52ff', 'Layover'),   # cyan\n",
    "        (17,  '#774c0b', 'Shadow'),   # brown\n",
    "        (18, 'black', 'upper-limit'),\n",
    "    ]\n",
    "    cvals = [x[0] for x in color_def]   # values, including upper-limit\n",
    "    cmap = [x[1] for x in color_def[0:-1]]   # colors, excluding upper-limit\n",
    "    cticks = [(x[0], f\"[{x[0]}] {x[2]}\") for x in color_def[0:-1]]  # labels, excluding upper-limit\n",
    "\n",
    "    # Image options\n",
    "    defaults = {\n",
    "        'aggregator': reductions.mode(),\n",
    "        'cmap': cmap,\n",
    "        'clim': (cvals[0], cvals[-1]),\n",
    "        'colorbar': True,\n",
    "        'frame_height': frame_height,\n",
    "    }\n",
    "    # Colorbar options for categories\n",
    "    extra_opts = {\n",
    "        'color_levels': cvals,\n",
    "        'cticks': cticks,\n",
    "    }\n",
    "    defaults.update(**kwargs)\n",
    "    return make_image(ds, **defaults).options(hv.opts.Image(**extra_opts))  #.hist(bins=bin_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0592571-8f7e-471b-acf4-57eb93563b25",
   "metadata": {},
   "source": [
    "## Filter scenes based on valid data\n",
    "\n",
    "This step is optional and configurable. Here we show another simple filter:\n",
    "\n",
    "- Exclude time layers with less than XX% valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c113df-101a-49d2-911e-5a83e77ad14a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Exclude time layers with less than XX% valid data\n",
    "\n",
    "data['mask'] = data.mask.persist()\n",
    "valid_data_mask = masking.valid_data_mask(data.mask)  # mask != mask.nodata -> bool\n",
    "selected = select_valid_time_layers(valid_data_mask, 20)  # Exclude time layers with less than 20% valid data\n",
    "data = data.sel(time=selected)\n",
    "\n",
    "display(xarray_object_size(data))\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d244be5-8895-4d71-b9af-4ce026e14e01",
   "metadata": {},
   "source": [
    "## Add dB and amplitude values to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961295e1-675b-4dda-92ba-c44b15506de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convenience loop for available polarization bands\n",
    "\n",
    "for pp in polarizations:\n",
    "    data[f\"{pp}_db\"] = dn_to_decibel(data[pp], K=-83).astype('float32')\n",
    "    data[f\"{pp}_amp\"] = dn_to_amplitude(data[pp]).astype('float32')\n",
    "\n",
    "display(xarray_object_size(data))\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f94783-ad8d-4c28-b145-091bd3a5c9ae",
   "metadata": {},
   "source": [
    "## Persist the data into the dask workers\n",
    "\n",
    "This will begin the data loading and calculations in the background.\n",
    "\n",
    "View progress in the dask dashboard (link given above where the dask cluster is defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4715d63-b9ee-410b-814d-f7b94730c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine for selected variables if not plotting/analysing everything\n",
    "data = data.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc56259-2e20-48f8-bab5-13ef56993bf9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot the data\n",
    "\n",
    "- Stronger co-polarization (VV) indicates direct backscatter while stronger cross-polarization (VH) may indicate a complex surface or volume scattering.\n",
    "- Amplitude data are linear-scaled so can tend to disciminate across a range of backscatter returns.\n",
    "- Decibel data are log-scaled so can tend to discriminate high and low backscatter returns.\n",
    "\n",
    "> Note the different data ranges for plotting (`clim`) between `vv`, `vh`, _amplitude_ and _dB_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b306030-ecb7-47b4-a63d-27fdb491c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VV, HH and HV (amplitude and dB) and Angle hvPlots\n",
    "\n",
    "clim = {\n",
    "    'vv_amp': (0, 0.5),\n",
    "    'hh_amp': (0, 0.5),\n",
    "    'hv_amp': (0, 0.25),\n",
    "    'vv_db': (-20, -5),\n",
    "    'hh_db': (-20, -5),\n",
    "    'hv_db': (-35, -10),\n",
    "}\n",
    "\n",
    "bands_plot_list = []\n",
    "for units in ('amplitude', 'dB'):\n",
    "    for pp in polarizations:\n",
    "        varname = f\"{pp}_{units[0:3].lower()}\"\n",
    "        title = f\"{pp.upper()} ({units})\"\n",
    "        bands_plot_list.append(\n",
    "            make_image(data[varname], title=title, clim=clim[varname])\n",
    "        )\n",
    "\n",
    "# Which is essentially doing this for all polarizations\n",
    "# vv_plot = make_image(data.vv_amp, title='VV (amplitude)', clim=(0, 0.5))\n",
    "# vv_db_plot = make_image(data.vv_db, title='VV (dB)', clim=(-20, -5))\n",
    "\n",
    "# # Add plots for the non-polarization bands\n",
    "bands_plot_list.append(make_image(data.angle, title='Incidence angle'))\n",
    "bands_plot_list.append(make_image(data.scatteringarea, title='Scattering area'))\n",
    "bands_plot_list.append(make_image(data.gammatosigmaratio, title='Gamma to sigma ratio'))\n",
    "bands_plot_list.append(mask_image(data.mask, title='Mask'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6531e1f9-d8c0-45bd-aeaa-f7e1c95bbc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange plots with linked axes and time slider. Adjust browser window width if required.\n",
    "\n",
    "num_plot_cols = 2 if len(polarizations) <= 2 else len(polarizations)\n",
    "layout = pn.panel(\n",
    "    hv.Layout(bands_plot_list).cols(num_plot_cols),\n",
    "    widget_location='top',\n",
    ")\n",
    "\n",
    "print(layout)  # Helpful to see how the hvplot is constructed\n",
    "display(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fbc6c5-4e0e-40c2-8c8f-82757ae0909b",
   "metadata": {},
   "source": [
    "## Plot histograms of the dB data\n",
    "\n",
    "A histogram can help separate water from land features. Here we show a histogram for the _dB_ channels for all time layers.\n",
    "- If the histogram shows two clear peaks then a value between the peaks could be used as a water / land threshold\n",
    "- If not then try selected time layers, a different area of interest, or other channels or combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a122cfe-f2bd-4b63-983c-c625e6849f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vals, bins, hist_plot = data.hv_db.plot.hist(bins=np.arange(-30, 0, 1), color='red')  # Matplotlib\n",
    "\n",
    "hist_plot_list = []\n",
    "for pp in polarizations:\n",
    "    varname = f\"{pp}_db\"\n",
    "    title = f\"{pp.upper()} (dB), combined times\"\n",
    "    hist_plot_list.append(\n",
    "        data[varname].hvplot.hist(bins=np.arange(-30, 0, 1), color='red', title=title, height=300)\n",
    "    )\n",
    "\n",
    "layout = hv.Layout(hist_plot_list).cols(len(polarizations))\n",
    "\n",
    "print(layout)  # Helpful to see how the hvplot is constructed\n",
    "display(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbb8282-3b77-43ce-a774-88b031fb94a3",
   "metadata": {},
   "source": [
    "## Make an RGB image\n",
    "\n",
    "A common strategy to create an RGB colour composite image for SAR data from two channels is to use the ratio of the channels to represent the third colour.\n",
    "\n",
    "Here we choose:\n",
    "\n",
    "- For a tri-pol (3 polarization bands) product we plot each polarization as red, green and blue.\n",
    "- For a dual-pol (2 polarization bands) product we plot each polarization as red and green and the ratio as blue.\n",
    "- For a single-pol (1 polarization band) product we can not make a useful RGB image\n",
    "\n",
    "Recall that:\n",
    "- VV or HH ... direct scattering\n",
    "- VH or HV ... complex scattering\n",
    "- ratio ... relatively more of one than the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082eeed7-dc16-4098-8bad-5dc748b6a79d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select bands combinations for RGB\n",
    "if len(polarizations) == 3:\n",
    "    rgb_bands = polarizations\n",
    "elif len(polarizations) == 2:\n",
    "    combo = \"_\".join(polarizations)\n",
    "    data[f\"{combo}\"] = data[polarizations[0]] / data[polarizations[1]]\n",
    "    rgb_bands = polarizations + [combo]\n",
    "else:\n",
    "    display(Markdown(\"**Can not make a useful RGB image from one polarization band**. Choose a dual- or tri-pol product\"))\n",
    "    rgb_bands = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a142d3-f278-49c8-a635-bb219675f239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if rgb_bands:\n",
    "    # Scale RGB bands by their median so they have a similar range for visualization\n",
    "    spatial_dims = data.odc.spatial_dims\n",
    "    for bb in rgb_bands:\n",
    "        data[f\"{bb}_scaled\"] = (data[bb] / data[bb].median(dim=spatial_dims))\n",
    "    rgb_bands = [f\"{bb}_scaled\" for bb in rgb_bands]\n",
    "\n",
    "    # odc-geo function\n",
    "    rgb_data = data.odc.to_rgba(bands=rgb_bands, vmin=0, vmax=2).persist()\n",
    "\n",
    "    # As subplots\n",
    "    # rgb_plot = rgb_image(\n",
    "    #     rgb_data,\n",
    "    # ).layout().cols(4)\n",
    "\n",
    "    # As movie. Select \"loop\" and use \"-\" button to adjust the speed to allow for rendering. After a few cycles the images should play reasonably well.\n",
    "    rgb_plot = rgb_image(\n",
    "        rgb_data,\n",
    "        precompute = True,\n",
    "        widget_type='scrubber', widget_location='bottom',\n",
    "        frame_height = 500,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2da45d-a1db-4d75-b725-706d0fa252c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if rgb_bands:\n",
    "    print(rgb_plot)  # Helpful to see how the hvplot is constructed\n",
    "    display(rgb_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1df15e-31e8-4ad8-9940-e28bd6822441",
   "metadata": {},
   "source": [
    "## Export to Geotiffs\n",
    "\n",
    "Recall that to write a dask dataset to a file requires the dataset to be `.compute()`ed. This may result in a large memory increase on your JupyterLab node if the area of interest is large enough, which in turn may kill the kernel. If so then skip this step, choose a smaller area or find a different way to export data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1347d080-74d5-491a-bb45-45252fc385ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a directory to save outputs to\n",
    "target = Path.home() / 'output'\n",
    "if not target.exists(): target.mkdir()\n",
    "\n",
    "def write_band(ds, varname):\n",
    "    \"\"\"Write the variable name of the xarray dataset to a Geotiff file for each time layer\"\"\"\n",
    "    for i in range(len(ds.time)):\n",
    "        date = ds[varname].isel(time=i).time.dt.strftime('%Y%m%d').data\n",
    "        fname = f'{target}/example_novasar-1_{varname}_{date}.tif'\n",
    "        single = ds[varname].isel(time=i).compute()\n",
    "        single.odc.write_cog(\n",
    "            fname=fname,\n",
    "            overwrite=True,\n",
    "        )\n",
    "        print(f'Wrote: {fname}')\n",
    "\n",
    "for pp in polarizations:\n",
    "    write_band(data, pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7c0753-3ba2-4736-acf0-3f52ca36bd17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
