{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4faa01-790c-4c1f-ac68-d46730fb570a",
   "metadata": {},
   "source": [
    "# On Chunks - The Art of Dask Part 1 <img align=\"right\" src=\"../../resources/csiro_easi_logo.png\">\n",
    "\n",
    "In this notebook we'll be exploring the impact of chunking choices for dask arrays. We'll use an ODC example but this isn't specific to ODC, it applies to all usage of dask `Array`s. Chunking choices have a _significant_ impact on performance for three reasons:\n",
    "1. Chunks are the unit of work during processing\n",
    "2. Chunks are the unit of transport in communicating information between workers\n",
    "3. Chunks are directly related to the number of _tasks_ being executed\n",
    "\n",
    "Performance is thus impacted in multiple ways - this is all about tradeoffs:\n",
    "* if chunks are too small, there will be too many _tasks_ and processing may be inefficient _BUT_\n",
    "* if chunks are too big, communication may be too long and the combined total of all chunks required for a calculation may exceed worker memory causing spilling to disk or worse, workers are killed\n",
    "\n",
    "It's not just size that matters either, the relative contiguity of dimensions matters:\n",
    "* Temporal processing is enhanced by larger chunks along the time dimension\n",
    "* Spatial processing is enhanced by larger chunks along the spatial dimensions, _BUT_\n",
    "* Earth Observation data can be sparse spatially, if chunks are too large spatially there will be a lot of empty chunks\n",
    "\n",
    "Thankfully it is possible to _re-chunk_ data for different stages of computation. Whilst _re-chunking is an *expensive* operation_ the efficiency gains for downstream computation can be very significant and sometimes are simply essential to support the numerical processing required. For example, it is often necessary to have a single chunk on the time dimension for temporal calculations.\n",
    "\n",
    "To understand the impact of chunking choices on _your code_ (it is very algorithm dependent) it is essential to understand both the:\n",
    "* _Static_ impact of chunking (e.g. task count, chunk size in memory), and;\n",
    "* _Dynamic_ impact of chunking (e.g. CPU load, thread utilisation, network communication, task count and scheduler load).\n",
    "\n",
    "`Dask` provides tools for viewing all of these when you print out arrays in the notebook (static) and when viewing the various graphs in the dask dashboard (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205583d7-7b6f-413a-819c-f3e2b6a1b0c9",
   "metadata": {},
   "source": [
    "## Our example\n",
    "\n",
    "The code below will be familiar, it's the same example from previous notebooks (seasonal mean NDVI over a large area). A normalised burn ratio (NBR2) calculation has been added as well to provide some additional load to assist in making the performance differences more noticeable in various graphs. The NBR2 uses two additional bands but is effectively the same type of calculation as the NDVI (a normalised difference ratio).\n",
    "\n",
    "The primary difference for this example is the calculation (both NDVI and NBR) is performed 4 times, each with a different chunking regime. See the `chunk_settings` list.\n",
    "\n",
    "__When running this notebook, be sure to have the dask dashboard open and preferably visible as calculations proceed.__\n",
    "\n",
    "There are several sections to pay attention too:\n",
    "* Status\n",
    "   * Short term snapshot of the Memory use (total and per worker - also shows Managed, Unmanaged and Spilled to Disk splits), Processing and CPU usage (change the Tab to switch between them)\n",
    "   * Progress of the optimized Task graph\n",
    "   * Near term Task Stream (Red is comms, White space is \"doing nothing\", other colours mostly match the tasks and you can hover over them with the mouse to get more information)\n",
    "* Tasks\n",
    "   * Longer term Task Stream. This is a more comprehensive and accurate view of the Execution over time\n",
    "* System\n",
    "   * Scheduler CPU, Memory and Communications load. You can zoom the graphs out using the control to get a longer term view.\n",
    "* Groups\n",
    "   * High level view of the Task Graph Groups and their execution. The actual task graph is too detailed to display so this provides some insight into how high level aspects of your algorithm are executing.\n",
    "\n",
    "_All_ of these graphs are dynamic and should be interpreted over time.\n",
    "\n",
    "The dask _scheduler_ itself is also dynamic and as your code executes it stores information about how the tasks are executing and the communication occuring and adjusts scheduling accordingly. It can take a few minutes for the scheduler to settle into a true pattern. That pattern may also change, particularly in latter parts of a computation when work is completing and there are fewer tasks to execute.\n",
    "\n",
    "Yes, that is a LOT of information. Thankfully you don't necessarily need to learn it all at once. In time, reading the information available will become easier as will knowing what to do about it.\n",
    "\n",
    "Now let's run this notebook, remember to watch the execution in the Dask Dashboard.\n",
    "\n",
    "> __Tip__: It's likely you will want to repeat the calculation in this notebook several times. Because the results are `persisted` to the cluster simply calling it again will result in no execution (none is required because it was `persisted`). Rather than doing `cluster.shutdown()` and creating a new cluster each time you can clear the `persisted` result by performing a `client.restart()`. This will clear out all previous calculations so you can `persist` again. You can do this either by creating a new cell or using a Python Console for this Notebook (right click on the notebook and select _New Console for Notebook_)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc395c36-548d-42bc-bd59-d4f390a6fc0a",
   "metadata": {},
   "source": [
    "### Create a cluster\n",
    "A modest cluster will do... _and Open the dashboard_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619a66a-c80f-4345-8022-a81018dc294f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the Gateway client\n",
    "from dask.distributed import Client\n",
    "from dask_gateway import Gateway\n",
    "\n",
    "number_of_workers = 5 \n",
    "\n",
    "gateway = Gateway()\n",
    "\n",
    "clusters = gateway.list_clusters()\n",
    "if not clusters:\n",
    "    print('Creating new cluster. Please wait for this to finish.')\n",
    "    cluster = gateway.new_cluster()\n",
    "else:\n",
    "    print(f'An existing cluster was found. Connecting to: {clusters[0].name}')\n",
    "    cluster=gateway.connect(clusters[0].name)\n",
    "\n",
    "cluster.scale(number_of_workers)\n",
    "\n",
    "client = cluster.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca446bdc-03b8-49bb-8489-13ad313a9a8f",
   "metadata": {},
   "source": [
    "### Setup all our functions and query parameters\n",
    "\n",
    "Nothing special here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008bc505-e1e7-44bf-9c95-d5bb7d96bda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyproj\n",
    "pyproj.set_use_global_context(True)\n",
    "\n",
    "import git\n",
    "import sys, os\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dask.distributed import Client, LocalCluster, wait\n",
    "import datacube\n",
    "from datacube.utils import masking\n",
    "from datacube.utils.aws import configure_s3_access\n",
    "\n",
    "# EASI defaults\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "repo = git.Repo('.', search_parent_directories=True).working_tree_dir\n",
    "if repo not in sys.path: sys.path.append(repo)\n",
    "from easi_tools import EasiDefaults, notebook_utils\n",
    "easi = EasiDefaults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8da7e0-5e0b-42a2-833b-ea60962581f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dc = datacube.Datacube()\n",
    "configure_s3_access(aws_unsigned=False, requester_pays=True, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a518ead6-750d-48ef-88f6-4fd4861eb939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the centroid of the coordinates of the default extents\n",
    "central_lat = sum(easi.latitude)/2\n",
    "central_lon = sum(easi.longitude)/2\n",
    "# central_lat = -42.019\n",
    "# central_lon = 146.615\n",
    "\n",
    "# Set the buffer to load around the central coordinates\n",
    "# This is a radial distance for the bbox to actual area so bbox 2x buffer in both dimensions\n",
    "buffer = 1\n",
    "\n",
    "# Compute the bounding box for the study area\n",
    "study_area_lat = (central_lat - buffer, central_lat + buffer)\n",
    "study_area_lon = (central_lon - buffer, central_lon + buffer)\n",
    "\n",
    "# Data product\n",
    "product = easi.product('landsat')\n",
    "\n",
    "# Set the date range to load data over\n",
    "set_time = easi.time\n",
    "set_time = (set_time[0], parse(set_time[0]) + relativedelta(months=6))\n",
    "#set_time = (\"2021-07-01\", \"2021-12-31\")\n",
    "\n",
    "# Selected measurement names (used in this notebook)\n",
    "alias = easi.aliases('landsat')\n",
    "measurements = [alias[x] for x in ['qa_band', 'red', 'nir', 'swir1', 'swir2']]\n",
    "\n",
    "# Set the QA band name and mask values\n",
    "qa_band = alias['qa_band']\n",
    "qa_mask = easi.qa_mask('landsat')\n",
    "\n",
    "# Set the resampling method for the bands\n",
    "resampling = {qa_band: \"nearest\", \"*\": \"average\"}\n",
    "\n",
    "# Set the coordinate reference system and output resolution\n",
    "set_crs = easi.crs('landsat')  # If defined, else None\n",
    "set_resolution = easi.resolution('landsat')  # If defined, else None\n",
    "# set_crs = \"epsg:3577\"\n",
    "# set_resolution = (-30, 30)\n",
    "\n",
    "# Set the scene group_by method\n",
    "group_by = \"solar_day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6ed74-06b4-4450-a7cd-25e487909878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_ndvi(dataset):\n",
    "    # Calculate the components that make up the NDVI calculation\n",
    "    band_diff = dataset[alias['nir']] - dataset[alias['red']]\n",
    "    band_sum = dataset[alias['nir']] + dataset[alias['red']]\n",
    "    # Calculate NDVI\n",
    "    ndvi = band_diff / band_sum\n",
    "    return ndvi\n",
    "\n",
    "def calc_nbr2(dataset):\n",
    "    # Calculate the components that make up the NDVI calculation\n",
    "    band_diff = dataset[alias['swir1']] - dataset[alias['swir2']]\n",
    "    band_sum = dataset[alias['swir1']] + dataset[alias['swir2']]\n",
    "    # Calculate NBR2\n",
    "    nbr2 = band_diff / band_sum\n",
    "    return nbr2\n",
    "\n",
    "def mask(dataset, bands):\n",
    "    # Identify pixels that are either \"valid\", \"water\" or \"snow\"\n",
    "    cloud_free_mask = masking.make_mask(dataset[qa_band], **qa_mask)\n",
    "    # Apply the mask\n",
    "    cloud_free = dataset[bands].astype('float32').where(cloud_free_mask)\n",
    "    return cloud_free\n",
    "\n",
    "def seasonal_mean(dataset):\n",
    "    return dataset.resample(time=\"QS-DEC\").mean('time') # perform the seasonal mean for each quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d30531-5747-4b70-9e47-aabd41f60b2e",
   "metadata": {},
   "source": [
    "We have an array of chunk settings to trial.\n",
    "\n",
    "* Notice the `chunk_settings` are nominally the same size\n",
    "* Notice we're varying the temporal chunking from large to small and adjusting the spatial chunking to keep the overall volume similar (nominally this will be 100 Megs per chunk for the original dataset)\n",
    "\n",
    "There are two `time:1` chunks because 50 doesn't have a clean sqrt. The first is the nearest square, the second simply changes the chunks to be rectangles (no one said the spatial dimensions needed to be the same).\n",
    "\n",
    "Given the chunk size in memory is roughly the same, the cluster the same, the calculation the same - any differences in execution are a result of the different chunking shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade0fc8-49a8-43e6-997a-60bae9d5c9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_settings = [\n",
    "    {\"chunks\": {\"time\":100, \"x\":300, \"y\":300}, \"comment\": \"This run has small spatial chunks but each chunk has a lot of time steps. This results in many small file reads, but there are more total tasks for the scheduler to handle.\"},\n",
    "    {\"chunks\": {\"time\":50, \"x\":1*300, \"y\":2*300}, \"comment\": \"This second run has slightly larger spatial chunks but smaller temporal extents in each chunk. This results in fewer total tasks, but each one takes longer to load.\"},\n",
    "    {\"chunks\": {\"time\":1, \"x\":10*300, \"y\":10*300}, \"comment\": \"This run has only a single time step in each chunk, but large, square spatial extents. As a result, workers need to store much more data in memory and some data is spilled to disk.\"},\n",
    "    {\"chunks\": {\"time\":1, \"x\":21*300, \"y\":5*300}, \"comment\": \"Again this run has a single time step per chunk, but the spatial extents are rectangles.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4ff1b-d512-4b6d-9f32-8fb0eeea9398",
   "metadata": {},
   "source": [
    "Now we can loop over all our `chunk_settings` and create all the required `delayed task graphs`. This will take a moment as the ODC database will be interogated for all the necessary dataset information.\n",
    "\n",
    "_You will notice the calculation is split up so we can see the interim results_ - well the last one at least given its a loop and we're overwriting them.\n",
    "\n",
    "Different stages of computation will produce different data types and calculations and thus _chunk_ and _task_ counts. We may find that an interim result has a terrible chunk size (e.g. `int16` data variables become `float64` and thus your chunks are now 4x the size, or a dimension is reduced and chunks are too small). It is thus advisable when tuning to make it possible to view these interim stages to see the _static_ impact.\n",
    "\n",
    "__Remember__: there is a single task graph executing to provide the final result. There is no need to `persist()` or `compute()` the interim results to see their _static_ attributes. In fact, it may be unwise to `persist()` as this will chew up resources on the cluster if you don't intend on using the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb9a27-c0d7-44d2-9823-e7f994ddf135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for chunkset in chunk_settings:\n",
    "    chunks = chunkset[\"chunks\"]\n",
    "    print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2276f-71be-4ac6-b29b-5e9ef96ab69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "results = []\n",
    "for chunkset in chunk_settings:\n",
    "    chunks = chunkset[\"chunks\"]\n",
    "    dataset = dc.load(\n",
    "                product=product,\n",
    "                x=study_area_lon,\n",
    "                y=study_area_lat,\n",
    "                time=set_time,\n",
    "                measurements=measurements,\n",
    "                resampling=resampling,\n",
    "                output_crs=set_crs,\n",
    "                resolution=set_resolution,\n",
    "                dask_chunks = chunks,\n",
    "                group_by=group_by,\n",
    "            )\n",
    "    \n",
    "    num_time = dataset.sizes['time']\n",
    "    time_ind = np.linspace(1, num_time, 100, dtype='int') - 1\n",
    "    dataset = dataset.isel(time=time_ind) # load exactly 100 evenly spaced timesteps so that we can work more easily with different chunks\n",
    "\n",
    "    masked_dataset = mask(dataset, [alias[x] for x in ['red', 'nir', 'swir1', 'swir2']])\n",
    "    ndvi = calc_ndvi(masked_dataset)\n",
    "    nbr2 = calc_nbr2(masked_dataset)\n",
    "    seasonal_mean_ndvi = seasonal_mean(ndvi)\n",
    "    seasonal_mean_nbr2 = seasonal_mean(nbr2)\n",
    "    seasonal_mean_ndvi.name = 'ndvi'\n",
    "    seasonal_mean_nbr2.name = 'nbr2'\n",
    "    results.append([seasonal_mean_ndvi, seasonal_mean_nbr2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac8a059-82d9-4188-8878-e7cc1dec7efe",
   "metadata": {},
   "source": [
    "### Inspecting _static_ information\n",
    "\n",
    "Lets take a look at the vital statistics for the final iteration of the loop. All the calculations are the same, just the `chunk` parameters vary so we can infer easily from these what else is happening for the _static_ parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb6bc3b-9872-4b11-8599-ba31f1ade74b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"dataset size (GiB) {dataset.nbytes / 2**30:.2f}\")\n",
    "print(f\"seasonal_mean_ndvi size (GiB) {seasonal_mean_ndvi.nbytes / 2**30:.2f}\")\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31183e67-0f5c-40d8-aee1-13a8f73da9a8",
   "metadata": {},
   "source": [
    "So the source `dataset` is 150 GB in size - mostly `int16` data type. _We need to be mindful that our calculation will convert these to `floats`._ The code above does an explicit type conversion to `float32` which can fully represent an `int16`. Without the explicit type conversion, Python would use `float64` resulting in double the memory usage for no good reason (for this algorithm).\n",
    "\n",
    "Open the _cylinder_ to show the `red` dask array details. The chunk is about 100 MiB in size. Generally this is a healthy size though it can be larger and may need to be smaller depending on the calculation involved and communication between workers.\n",
    "\n",
    "Now let's look at the results for the NDVI and NBR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ab0c2f-05f8-4ca7-8dd8-789c63d143df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(results[0][0])\n",
    "display(results[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0a747-5629-48d3-b0c7-de9035c96f01",
   "metadata": {},
   "source": [
    "Notice the result is _much smaller_ in chunk size - 4 MiB. This is due to the seasonal mean. This may have an impact on downstream usage of the result as the _chunks_ may be too small and result in too many tasks reducing later processing performance.\n",
    "\n",
    "Notice also the Task count. With both results we're pushing towards 100_000 tasks in the scheduler depending on task graph optimisation. The Scheduler has its own overheads (about 1ms per active task, and memory usage for tracking all tasks, including executed ones as it keeps the history in case it needs to reproduce the results e.g. if a worker is lost). Again, it is possible to have more than 100_000 tasks and be efficient depending on your algorithm but its something to keep an eye on. We will be below it in this case (especially after optimisation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee97957f-7959-422d-b9ae-a47750aa4b50",
   "metadata": {},
   "source": [
    "### Persist the results\n",
    "\n",
    "Theoretically we could `persist` all of the `results` at once - though we would be well above the 100_000 task limit if we did.\n",
    "More importantly we actually want to see the difference in the _dynamics_ of the execution.\n",
    "The loop below will persist each result one at a time and _wait()_ for it to be complete.\n",
    "\n",
    "__You should monitor execution in the Dask Dashboard__\n",
    "\n",
    "Look at the various tabs as execution proceeds. you will notice differences in memory per worker, Communication between workers (red bars in the Task Stream), white space (idle time), and CPU utilisation (remember to click on the CPU tab to get to this detail).\n",
    "The `Tasks` section of the dashboard is particularly useful at looking at a comparison of all four runs' dynamics as the length of all calculations means this snapshot still show all four blocks of computation at once.\n",
    "\n",
    "Don't forget, if you want to run the code again use `client.restart()` to clear out the previous results from the cluster.\n",
    "\n",
    ">__Tip:__ If you leave your computer while this step is running, make sure that it doesn't go to sleep by adjusting your power settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a306aa-86e7-432a-bdfc-b4ecf20e8aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client.wait_for_workers(n_workers=number_of_workers)\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f'Run number {i+1}:')\n",
    "    print(f'Chunks: {chunk_settings[i][\"chunks\"]}')\n",
    "    print(chunk_settings[i][\"comment\"])\n",
    "    client.restart()\n",
    "    f = client.persist(result)\n",
    "    %time wait(f)\n",
    "    client.restart() # clearing the cluster out so each run it cleanly separated\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e2de7-2e11-4edf-bf14-6ca1d0b81a6a",
   "metadata": {},
   "source": [
    "## Understanding the dynamics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcad62-a6e4-4504-9e41-d33f872ade7a",
   "metadata": {},
   "source": [
    "# Be a good dask user - Clean up the cluster resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66acca97-686c-4d09-ba5b-a9aeede4bfba",
   "metadata": {},
   "source": [
    "Disconnecting your client is good practice, but the cluster will still be up so we need to shut it down as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0578682e-917e-49b7-9f3e-88584a572936",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de2e63e-138d-401e-944d-27520d3ad8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
